{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd08d466f5fa6fb18530bca1f949177b1fcfe59f60d945432f26594dff26bd69283",
   "display_name": "Python 3.8.5 64-bit ('py3_tensorflow_env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8d466f5fa6fb18530bca1f949177b1fcfe59f60d945432f26594dff26bd69283"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv(csv_file):\n",
    "    # Read csv with the following name of columns\n",
    "    df = pd.read_csv(csv_file, header=None, sep=\":\", names=[\"CPU\", \"Value\", \"Unit\", \"Event Name\"])\n",
    "\n",
    "    # Define the number of epochs and number of measures\n",
    "    num_epochs = 30\n",
    "    num_measures = 5\n",
    "\n",
    "    # Get the events measured\n",
    "    events = df[\"Event Name\"].unique()\n",
    "\n",
    "    # Split the Dataframe in num_measures\n",
    "    arrs = np.array_split(df, num_measures)\n",
    "\n",
    "    # Store that mean columns in a new Dataframe\n",
    "    data = []\n",
    "    headers = []\n",
    "    i = 0\n",
    "    # Calculate the mean of each iteration\n",
    "    for arr in arrs:\n",
    "        arr = arr.reset_index(drop=True)\n",
    "        arr['Avg'] = arr.groupby('Event Name')['Value'].transform('sum')\n",
    "        i = i + 1\n",
    "        headers.append(\"Measure_\" + str(i))\n",
    "        data.append(arr['Avg'].head(len(events)))\n",
    "\n",
    "    # Creates a new df from the avg of the iters\n",
    "    df = pd.concat(data, axis=1, keys=headers)\n",
    "\n",
    "    # Add the events names\n",
    "    df.insert(0, 'Event Name', events)\n",
    "\n",
    "    # Creates a new avg column from all the measures\n",
    "    df['Avg'] = df.mean(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv and create excel file from it\n",
    "csv_file = \"/home/jlpadillas01/TFG/tests/tensorflow/mnist/out/mnist_train_each_batch_CUIDADO.csv\"\n",
    "df = df_from_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 Event Name     Measure_1     Measure_2  \\\n",
       "0                PERF_COUNT_HW_INSTRUCTIONS  196028646105  194718272452   \n",
       "1         PERF_COUNT_HW_BRANCH_INSTRUCTIONS   16899903233   16628859364   \n",
       "2                           L1-DCACHE-LOADS   67046626626   66662987066   \n",
       "3                          L1-DCACHE-STORES   14487138800   14271988592   \n",
       "4       fp_arith_inst_retired.scalar_double     247821163     247611302   \n",
       "5       fp_arith_inst_retired.scalar_single     155507746     155504693   \n",
       "6  fp_arith_inst_retired.128b_packed_single      15135996      15135704   \n",
       "7  fp_arith_inst_retired.256b_packed_single       3421158       3421092   \n",
       "8  fp_arith_inst_retired.512b_packed_single  123342950370  123340570870   \n",
       "\n",
       "      Measure_3     Measure_4     Measure_5           Avg  \n",
       "0  194861488225  194880997876  194796944735  1.950573e+11  \n",
       "1   16655877660   16664408861   16648518729  1.669951e+10  \n",
       "2   66719640026   66715521981   66703393050  6.676963e+10  \n",
       "3   14320188067   14307957565   14314735170  1.434040e+10  \n",
       "4     247809540     247815120     247793334  2.477701e+08  \n",
       "5     155507693     155504693     155504693  1.555059e+08  \n",
       "6      15135996      15135704      15135704  1.513582e+07  \n",
       "7       3421158       3421092       3421092  3.421118e+06  \n",
       "8  123342950370  123340570870  123340570870  1.233415e+11  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Event Name</th>\n      <th>Measure_1</th>\n      <th>Measure_2</th>\n      <th>Measure_3</th>\n      <th>Measure_4</th>\n      <th>Measure_5</th>\n      <th>Avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PERF_COUNT_HW_INSTRUCTIONS</td>\n      <td>196028646105</td>\n      <td>194718272452</td>\n      <td>194861488225</td>\n      <td>194880997876</td>\n      <td>194796944735</td>\n      <td>1.950573e+11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PERF_COUNT_HW_BRANCH_INSTRUCTIONS</td>\n      <td>16899903233</td>\n      <td>16628859364</td>\n      <td>16655877660</td>\n      <td>16664408861</td>\n      <td>16648518729</td>\n      <td>1.669951e+10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L1-DCACHE-LOADS</td>\n      <td>67046626626</td>\n      <td>66662987066</td>\n      <td>66719640026</td>\n      <td>66715521981</td>\n      <td>66703393050</td>\n      <td>6.676963e+10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L1-DCACHE-STORES</td>\n      <td>14487138800</td>\n      <td>14271988592</td>\n      <td>14320188067</td>\n      <td>14307957565</td>\n      <td>14314735170</td>\n      <td>1.434040e+10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fp_arith_inst_retired.scalar_double</td>\n      <td>247821163</td>\n      <td>247611302</td>\n      <td>247809540</td>\n      <td>247815120</td>\n      <td>247793334</td>\n      <td>2.477701e+08</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>fp_arith_inst_retired.scalar_single</td>\n      <td>155507746</td>\n      <td>155504693</td>\n      <td>155507693</td>\n      <td>155504693</td>\n      <td>155504693</td>\n      <td>1.555059e+08</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>fp_arith_inst_retired.128b_packed_single</td>\n      <td>15135996</td>\n      <td>15135704</td>\n      <td>15135996</td>\n      <td>15135704</td>\n      <td>15135704</td>\n      <td>1.513582e+07</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fp_arith_inst_retired.256b_packed_single</td>\n      <td>3421158</td>\n      <td>3421092</td>\n      <td>3421158</td>\n      <td>3421092</td>\n      <td>3421092</td>\n      <td>3.421118e+06</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fp_arith_inst_retired.512b_packed_single</td>\n      <td>123342950370</td>\n      <td>123340570870</td>\n      <td>123342950370</td>\n      <td>123340570870</td>\n      <td>123340570870</td>\n      <td>1.233415e+11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          CPU       Value  Unit                                Event Name\n",
       "0           2  1121200835   NaN                PERF_COUNT_HW_INSTRUCTIONS\n",
       "1           2   231256906   NaN         PERF_COUNT_HW_BRANCH_INSTRUCTIONS\n",
       "2           2   323762220   NaN                           L1-DCACHE-LOADS\n",
       "3           2   173377936   NaN                          L1-DCACHE-STORES\n",
       "4           2       11887   NaN       fp_arith_inst_retired.scalar_double\n",
       "...       ...         ...   ...                                       ...\n",
       "69987235   31           0   NaN       fp_arith_inst_retired.scalar_double\n",
       "69987236   31           0   NaN       fp_arith_inst_retired.scalar_single\n",
       "69987237   31           0   NaN  fp_arith_inst_retired.128b_packed_single\n",
       "69987238   31           0   NaN  fp_arith_inst_retired.256b_packed_single\n",
       "69987239   31           0   NaN  fp_arith_inst_retired.512b_packed_single\n",
       "\n",
       "[69987240 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CPU</th>\n      <th>Value</th>\n      <th>Unit</th>\n      <th>Event Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1121200835</td>\n      <td>NaN</td>\n      <td>PERF_COUNT_HW_INSTRUCTIONS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>231256906</td>\n      <td>NaN</td>\n      <td>PERF_COUNT_HW_BRANCH_INSTRUCTIONS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>323762220</td>\n      <td>NaN</td>\n      <td>L1-DCACHE-LOADS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>173377936</td>\n      <td>NaN</td>\n      <td>L1-DCACHE-STORES</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>11887</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_double</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69987235</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_double</td>\n    </tr>\n    <tr>\n      <th>69987236</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_single</td>\n    </tr>\n    <tr>\n      <th>69987237</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.128b_packed_single</td>\n    </tr>\n    <tr>\n      <th>69987238</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.256b_packed_single</td>\n    </tr>\n    <tr>\n      <th>69987239</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.512b_packed_single</td>\n    </tr>\n  </tbody>\n</table>\n<p>69987240 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          CPU       Value  Unit                                Event Name\n",
       "0           2  1121200835   NaN                PERF_COUNT_HW_INSTRUCTIONS\n",
       "1           2   231256906   NaN         PERF_COUNT_HW_BRANCH_INSTRUCTIONS\n",
       "2           2   323762220   NaN                           L1-DCACHE-LOADS\n",
       "3           2   173377936   NaN                          L1-DCACHE-STORES\n",
       "4           2       11887   NaN       fp_arith_inst_retired.scalar_double\n",
       "...       ...         ...   ...                                       ...\n",
       "69619495   31           0   NaN       fp_arith_inst_retired.scalar_double\n",
       "69619496   31           0   NaN       fp_arith_inst_retired.scalar_single\n",
       "69619497   31           0   NaN  fp_arith_inst_retired.128b_packed_single\n",
       "69619498   31           0   NaN  fp_arith_inst_retired.256b_packed_single\n",
       "69619499   31           0   NaN  fp_arith_inst_retired.512b_packed_single\n",
       "\n",
       "[69619500 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CPU</th>\n      <th>Value</th>\n      <th>Unit</th>\n      <th>Event Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1121200835</td>\n      <td>NaN</td>\n      <td>PERF_COUNT_HW_INSTRUCTIONS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>231256906</td>\n      <td>NaN</td>\n      <td>PERF_COUNT_HW_BRANCH_INSTRUCTIONS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>323762220</td>\n      <td>NaN</td>\n      <td>L1-DCACHE-LOADS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>173377936</td>\n      <td>NaN</td>\n      <td>L1-DCACHE-STORES</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>11887</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_double</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69619495</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_double</td>\n    </tr>\n    <tr>\n      <th>69619496</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.scalar_single</td>\n    </tr>\n    <tr>\n      <th>69619497</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.128b_packed_single</td>\n    </tr>\n    <tr>\n      <th>69619498</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.256b_packed_single</td>\n    </tr>\n    <tr>\n      <th>69619499</th>\n      <td>31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>fp_arith_inst_retired.512b_packed_single</td>\n    </tr>\n  </tbody>\n</table>\n<p>69619500 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute path to this file\n",
    "MY_PAPI_DIR = pathlib.Path().absolute()\n",
    "# Now, we have to move to the root of this workspace ([prev. path]/TFG)\n",
    "MY_PAPI_DIR = MY_PAPI_DIR.parent.parent.parent.parent.absolute()\n",
    "# From the root (TFG/) access to my_papi dir. and its content\n",
    "MY_PAPI_DIR = MY_PAPI_DIR / \"my_papi\"\n",
    "# Folder where the configuration files are located\n",
    "CFG_DIR = MY_PAPI_DIR / \"conf\"\n",
    "# Folder where the library is located\n",
    "LIB_DIR = MY_PAPI_DIR / \"lib\"\n",
    "# Folder where the source codes are located\n",
    "SRC_DIR = MY_PAPI_DIR / \"src\"\n",
    "\n",
    "# Add the source path and import the library\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "from MyPapi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_iter(csv_file):\n",
    "\n",
    "    # Read csv with the following name of columns\n",
    "    df = pd.read_csv(csv_file, header=None, sep=\":\",\n",
    "                        names=[\"CPU\", \"Value\", \"Unit\", \"Event Name\"])\n",
    "\n",
    "    # Get the events and cpus measured\n",
    "    events = df[\"Event Name\"].unique()\n",
    "    cpus = df[\"CPU\"].unique()\n",
    "\n",
    "    # Also the number of iterations (batch_size, epoch, etc)\n",
    "    num_measures = int(len(df.index) / (len(events) * len(cpus)))\n",
    "\n",
    "    # Creates a column with the number of iteration\n",
    "    df.insert(0, \"# Measure\", 0)\n",
    "\n",
    "    # We have to modify them depending on the number of measures and cpus\n",
    "    aux = 0\n",
    "    for i in range(num_measures, 0, -1):\n",
    "        aux += 1\n",
    "        df.loc[df.index[-i * len(events) * len(cpus):], \"# Measure\"] = aux\n",
    "\n",
    "    # \"Rotate\" the table\n",
    "    df = df.pivot_table(index=[\"# Measure\", \"CPU\"], columns=[\n",
    "        \"Event Name\"], values=[\"Value\"]).fillna(0)\n",
    "\n",
    "    # Drop the first multiindex\n",
    "    df.columns = df.columns.droplevel()\n",
    "\n",
    "    # Add columns with rates (IPC, acc., etc.)\n",
    "    df = MyPapi.get_rates_from_df(df)\n",
    "\n",
    "    # Remove name of columns\n",
    "    df.columns.name = None\n",
    "    # Reset the index to an auto-increment\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # No need of CPU column\n",
    "    df = df.drop([\"CPU\"], axis=1)\n",
    "\n",
    "    # Get the list of measures\n",
    "    measures = df[\"# Measure\"].unique()\n",
    "    events = df.columns\n",
    "\n",
    "    # Array with 'num_measures' dicts as entries\n",
    "    arr_measures = [{} for _ in measures]\n",
    "\n",
    "    # Store the data\n",
    "    for i in range(0, len(measures)):\n",
    "        for e in events:\n",
    "            dict_aux = arr_measures[i]\n",
    "            dict_aux[e] = df.loc[df[\"# Measure\"] == measures[i], e].mean()\n",
    "\n",
    "    # Convert to pandas Dataframe\n",
    "    df = pd.DataFrame(arr_measures)\n",
    "    # Set the # Measure column as index\n",
    "    df = df.set_index(\"# Measure\")\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    # Array with the figures/html files to create\n",
    "    figs = [go.Figure(),\n",
    "            make_subplots(\n",
    "                rows=1, cols=2,\n",
    "                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]],\n",
    "                subplot_titles=(\"Rates\", \"Derived metrics\"))\n",
    "            ]\n",
    "\n",
    "    # Add the value to the graphs\n",
    "    for col in df.columns:\n",
    "        if col not in events_dict.keys():\n",
    "            figs[0].add_trace(\n",
    "                go.Scatter(x=df.index.values.tolist(), y=df[col], name=col)\n",
    "            )\n",
    "        else:\n",
    "            if \"rate\" in col:\n",
    "                figs[1].add_trace(\n",
    "                    go.Scatter(x=df.index.values.tolist(),\n",
    "                                y=df[col] * 100, name=col),\n",
    "                    row=1, col=1, secondary_y=False\n",
    "                )\n",
    "            else:\n",
    "                figs[1].add_trace(\n",
    "                    go.Scatter(x=df.index.values.tolist(),\n",
    "                                y=df[col], name=col),\n",
    "                    row=1, col=2, secondary_y=False\n",
    "                )\n",
    "    # Change the name of the y axis\n",
    "    figs[0].update_yaxes(title_text=\"Value\")\n",
    "    figs[1].update_yaxes(title_text=\"Miss rate (%)\", row=1, col=1)\n",
    "    figs[1].update_yaxes(title_text=\"Value\", row=1, col=2)\n",
    "            \n",
    "    # Set options common to all traces with fig.update_traces\n",
    "    for fig in figs:\n",
    "        fig.update_traces(mode='lines+markers',\n",
    "                            marker_line_width=2, marker_size=8)\n",
    "        fig.update_layout(\n",
    "            title='MyPaPi measure by iterations: ' + csv_file,\n",
    "            # yaxis_zeroline=False, xaxis_zeroline=False,\n",
    "            hovermode=\"x unified\",\n",
    "            legend=dict(\n",
    "                # x=-1,\n",
    "                # y=-1,\n",
    "                traceorder=\"normal\",\n",
    "                font=dict(family=\"sans-serif\",\n",
    "                            size=12,\n",
    "                            color=\"black\"),\n",
    "                bgcolor=\"white\",\n",
    "                bordercolor=\"Black\",\n",
    "                borderwidth=2\n",
    "            )\n",
    "        )\n",
    "        fig.update_xaxes(range=[0, len(measures) + 1],\n",
    "                            title_text=\"Number of measure\")\n",
    "        # ! Open the files when end the execution\n",
    "        #fig.show()\n",
    "\n",
    "    # Save the html files\n",
    "    name_html = csv_file + \"_1_.html\"\n",
    "    figs[0].write_html(name_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import pandas as pd\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# Create server variable with Flask server object for use with gunicorn\n",
    "# server = app.server\n",
    "\n",
    "# df = pd.read_csv('https://plotly.github.io/datasets/country_indicators.csv')\n",
    "# available_indicators = df['Indicator Name'].unique()\n",
    "\n",
    "\n",
    "df = px.data.iris()\n",
    "all_dims = ['sepal_length', 'sepal_width', \n",
    "            'petal_length', 'petal_width']\n",
    "\n",
    "# app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id=\"dropdown\",\n",
    "        options=[{\"label\": x, \"value\": x} \n",
    "                 for x in all_dims],\n",
    "        value=all_dims[:2],\n",
    "        multi=True\n",
    "    ),\n",
    "    dcc.Graph(id=\"splom\"),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"splom\", \"figure\"), \n",
    "    [Input(\"dropdown\", \"value\")])\n",
    "def update_bar_chart(dims):\n",
    "    fig = px.scatter_matrix(\n",
    "        df, dimensions=dims, color=\"species\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "app.run_server(mode=\"jupyterlab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "csv_file = \"/home/jlpadillas01/TFG/tests/tensorflow/mnist/out/single_thread/mnist_train_each_epoch.csv\"\n",
    "df = df_from_csv_for_plot(csv_file)\n",
    "\n",
    "#Declaración del estilo\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Tahoma'\n",
    "plt.rcParams['xtick.color']='#A8A8A9'\n",
    "plt.rcParams['ytick.color']='#A8A8A9'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "\n",
    "x_values = df['# Iter.']\n",
    "y_values = df['fp_arith_inst_retired.512b_packed_single'].tolist()\n",
    "\n",
    "plt.plot(x_values, y_values, marker='o') # color='#a12424'\n",
    "\n",
    "plt.title('Evol. event per epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Event')\n",
    "plt.legend(['fp_arith_inst_retired.512b_packed_single'], loc=3)\n",
    "plt.ylim(ymin=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('test.jpg')"
   ]
  }
 ]
}